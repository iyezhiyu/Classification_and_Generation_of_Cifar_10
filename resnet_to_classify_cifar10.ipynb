{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CwxWCyqKw6u5"
   },
   "source": [
    "# Use Resnet to classify Cifar-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 131
    },
    "colab_type": "code",
    "id": "YjJMiUxSw6vB",
    "outputId": "d4343fe1-911a-4511-d884-295fa13646fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A9LYujkFw6vG"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JymhS_jiw6vH"
   },
   "source": [
    "This project is to build a ResNet and use it to classify Cifar-10 dataset.\n",
    "The ResNet architecture is introduced in 2015 by Kaiming He, et al. in the paper [\"Deep residual learning for image recognition\"](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Extf5Kvw6vO"
   },
   "source": [
    "## Implement ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0JLAagD6X4z"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7IPDT5tBw6vT"
   },
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    \n",
    "    def __init__(self, inchannel, outchannel, kernel_size, stride, padding, bias = True):\n",
    "        \n",
    "        super(Conv2D, self).__init__()\n",
    "        \n",
    "        self.inchannel = inchannel\n",
    "        self.outchannel = outchannel\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "        self.weights = nn.Parameter(torch.Tensor(outchannel, inchannel, \n",
    "                                                 kernel_size, kernel_size))\n",
    "        #self.weights.data.normal_(-0.1, 0.1)\n",
    "        self.weights = nn.init.kaiming_normal_(self.weights)\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(outchannel, ))\n",
    "            self.bias.data.normal_(-0.1, 0.1)\n",
    "        else:\n",
    "            self.bias = None\n",
    "            \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        unfold = nn.Unfold(kernel_size = (self.kernel_size, self.kernel_size), padding = self.padding, stride = self.stride).to('cuda')\n",
    "        inp_unf = unfold(x).to('cuda')\n",
    "        out_unf = inp_unf.transpose(1,2).matmul(self.weights.view(self.weights.size(0), -1).t()).transpose(1,2).to('cuda')\n",
    "        x_out = (x.size(2)+2*self.padding - self.kernel_size)//self.stride + 1\n",
    "        y_out = (x.size(3)+2*self.padding - self.kernel_size)//self.stride + 1\n",
    "        output = F.fold(out_unf, (x_out, y_out), (1, 1)).to('cuda')        \n",
    "\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GIl7W-hw6vV"
   },
   "outputs": [],
   "source": [
    "class MaxPool2D(nn.Module):\n",
    "    \n",
    "    def __init__(self, pooling_size):\n",
    "        # assume pooling_size = kernel_size = stride\n",
    "        \n",
    "        super(MaxPool2D, self).__init__()\n",
    "        \n",
    "        self.pooling_size = pooling_size\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #output = torch.zeros(x.size(0),x.size(1),x.size(2)//self.pooling_size, x.size(3)//self.pooling_size).to('cuda')\n",
    "        #for i in range(0,x.size(2),self.pooling_size):\n",
    "        #    for j in range(0,x.size(3),self.pooling_size):\n",
    "        #        t = x[:,:,i:i+self.pooling_size,j:j+self.pooling_size].to('cuda')\n",
    "        #        t = t.flatten(start_dim = 2).to('cuda')\n",
    "        #        t = t.max(dim =2)\n",
    "        #        output[:,:,i//self.pooling_size, j//self.pooling_size] = t[0].to('cuda')\n",
    "        \n",
    "        ### without loop method\n",
    "        N, C_in, H_in, W_in = x.shape\n",
    "        \n",
    "        x_reshaped = x.reshape([N, C_in, H_in // self.pooling_size, self.pooling_size, \n",
    "                           W_in // self.pooling_size, self.pooling_size])\n",
    "        \n",
    "        out, _ = x_reshaped.max(3)\n",
    "        \n",
    "        output, _ = out.max(4)\n",
    "                \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2bBhs3_6X5H"
   },
   "outputs": [],
   "source": [
    "# define resnet building blocks\n",
    "\n",
    "class ResidualBlock(nn.Module): \n",
    "    def __init__(self, inchannel, outchannel, stride=1): \n",
    "        \n",
    "        super(ResidualBlock, self).__init__() \n",
    "        \n",
    "        self.left = nn.Sequential(Conv2D(inchannel, outchannel, kernel_size=3, \n",
    "                                         stride=stride, padding=1, bias=False), \n",
    "                                  nn.BatchNorm2d(outchannel), \n",
    "                                  nn.ReLU(inplace=True), \n",
    "                                  Conv2D(outchannel, outchannel, kernel_size=3, \n",
    "                                         stride=1, padding=1, bias=False), \n",
    "                                  nn.BatchNorm2d(outchannel)) \n",
    "        \n",
    "        self.shortcut = nn.Sequential() \n",
    "        \n",
    "        if stride != 1 or inchannel != outchannel: \n",
    "            \n",
    "            self.shortcut = nn.Sequential(Conv2D(inchannel, outchannel, \n",
    "                                                 kernel_size=1, stride=stride, \n",
    "                                                 padding = 0, bias=False), \n",
    "                                          nn.BatchNorm2d(outchannel) ) \n",
    "            \n",
    "    def forward(self, x): \n",
    "        \n",
    "        out = self.left(x) \n",
    "        \n",
    "        out += self.shortcut(x) \n",
    "        \n",
    "        out = F.relu(out) \n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U-Sa0BAw6X5P"
   },
   "outputs": [],
   "source": [
    "# define resnet\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, ResidualBlock, num_classes = 10):\n",
    "        \n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(Conv2D(3, 64, kernel_size = 3, stride = 1,\n",
    "                                            padding = 1, bias = False), \n",
    "                                  nn.BatchNorm2d(64), \n",
    "                                  nn.ReLU())\n",
    "        \n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64, 2, stride = 1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride = 2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride = 2)\n",
    "        self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride = 2)\n",
    "        self.maxpool = MaxPool2D(4)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    \n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        \n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        \n",
    "        layers = []\n",
    "        \n",
    "        for stride in strides:\n",
    "            \n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            \n",
    "            self.inchannel = channels\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "def ResNet18():\n",
    "    return ResNet(ResidualBlock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pUMQU0fTw6vc"
   },
   "source": [
    "## Train ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "jx4EjUPa6X5d",
    "outputId": "aaf1b9e7-a650-46a1-f0ec-1a0c2ed911f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "transform = T.ToTensor()\n",
    "\n",
    "\n",
    "# load data\n",
    "\n",
    "NUM_TRAIN = 49000\n",
    "print_every = 100\n",
    "\n",
    "\n",
    "data_dir = './data'\n",
    "cifar10_train = dset.CIFAR10(data_dir, train=True, download=True, transform=transform)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10(data_dir, train=True, download=True, transform=transform)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10(data_dir, train=False, download=True, transform=transform)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)\n",
    "\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32 \n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lcscd7k66X5s"
   },
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    # function for test accuracy on validation and test set\n",
    "    \n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "\n",
    "\n",
    "def train_part(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        print(len(loader_train))\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the parameters of the model using the gradients\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Epoch: %d, Iteration %d, loss = %.4f' % (e, t, loss.item()))\n",
    "                #check_accuracy(loader_val, model)\n",
    "                print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1547
    },
    "colab_type": "code",
    "id": "no8o-2VS6X5y",
    "outputId": "ce84369c-ce1d-4659-d9af-f69131811ed3",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "766\n",
      "Epoch: 0, Iteration 0, loss = 2.9305\n",
      "\n",
      "Epoch: 0, Iteration 100, loss = 1.5960\n",
      "\n",
      "Epoch: 0, Iteration 200, loss = 1.5995\n",
      "\n",
      "Epoch: 0, Iteration 300, loss = 1.0909\n",
      "\n",
      "Epoch: 0, Iteration 400, loss = 1.1119\n",
      "\n",
      "Epoch: 0, Iteration 500, loss = 1.4162\n",
      "\n",
      "Epoch: 0, Iteration 600, loss = 0.7753\n",
      "\n",
      "Epoch: 0, Iteration 700, loss = 1.0101\n",
      "\n",
      "766\n",
      "Epoch: 1, Iteration 0, loss = 0.6692\n",
      "\n",
      "Epoch: 1, Iteration 100, loss = 0.7235\n",
      "\n",
      "Epoch: 1, Iteration 200, loss = 0.7129\n",
      "\n",
      "Epoch: 1, Iteration 300, loss = 0.6694\n",
      "\n",
      "Epoch: 1, Iteration 400, loss = 0.7546\n",
      "\n",
      "Epoch: 1, Iteration 500, loss = 0.5350\n",
      "\n",
      "Epoch: 1, Iteration 600, loss = 0.6856\n",
      "\n",
      "Epoch: 1, Iteration 700, loss = 0.5922\n",
      "\n",
      "766\n",
      "Epoch: 2, Iteration 0, loss = 0.4598\n",
      "\n",
      "Epoch: 2, Iteration 100, loss = 0.3009\n",
      "\n",
      "Epoch: 2, Iteration 200, loss = 0.4092\n",
      "\n",
      "Epoch: 2, Iteration 300, loss = 0.5850\n",
      "\n",
      "Epoch: 2, Iteration 400, loss = 0.4897\n",
      "\n",
      "Epoch: 2, Iteration 500, loss = 0.4609\n",
      "\n",
      "Epoch: 2, Iteration 600, loss = 0.3813\n",
      "\n",
      "Epoch: 2, Iteration 700, loss = 0.4292\n",
      "\n",
      "766\n",
      "Epoch: 3, Iteration 0, loss = 0.4875\n",
      "\n",
      "Epoch: 3, Iteration 100, loss = 0.3132\n",
      "\n",
      "Epoch: 3, Iteration 200, loss = 0.1802\n",
      "\n",
      "Epoch: 3, Iteration 300, loss = 0.3611\n",
      "\n",
      "Epoch: 3, Iteration 400, loss = 0.4169\n",
      "\n",
      "Epoch: 3, Iteration 500, loss = 0.2517\n",
      "\n",
      "Epoch: 3, Iteration 600, loss = 0.3479\n",
      "\n",
      "Epoch: 3, Iteration 700, loss = 0.2944\n",
      "\n",
      "766\n",
      "Epoch: 4, Iteration 0, loss = 0.2165\n",
      "\n",
      "Epoch: 4, Iteration 100, loss = 0.1177\n",
      "\n",
      "Epoch: 4, Iteration 200, loss = 0.2316\n",
      "\n",
      "Epoch: 4, Iteration 300, loss = 0.1845\n",
      "\n",
      "Epoch: 4, Iteration 400, loss = 0.2415\n",
      "\n",
      "Epoch: 4, Iteration 500, loss = 0.3025\n",
      "\n",
      "Epoch: 4, Iteration 600, loss = 0.1339\n",
      "\n",
      "Epoch: 4, Iteration 700, loss = 0.3536\n",
      "\n",
      "Checking accuracy on test set\n",
      "Got 8309 / 10000 correct (83.09)\n"
     ]
    }
   ],
   "source": [
    "# code for optimising network performance\n",
    "\n",
    "del cifar10_train\n",
    "del loader_train\n",
    "del cifar10_val\n",
    "del loader_val\n",
    "del cifar10_test\n",
    "del loader_test\n",
    "\n",
    "\n",
    "data_transforms = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        #T.Normalize([0.4914, 0.4822, 0.4465], [0.247, 0.243, 0.261]),\n",
    "        T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "\n",
    "cifar10_train = dset.CIFAR10(data_dir, train=True, download=True, transform=data_transforms)\n",
    "loader_train = DataLoader(cifar10_train, batch_size=64,\n",
    "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
    "\n",
    "cifar10_val = dset.CIFAR10(data_dir, train=True, download=True, transform=data_transforms)\n",
    "loader_val = DataLoader(cifar10_val, batch_size=64,\n",
    "                        sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
    "\n",
    "cifar10_test = dset.CIFAR10(data_dir, train=False, download=True, transform=data_transforms)\n",
    "loader_test = DataLoader(cifar10_test, batch_size=64)\n",
    "\n",
    "\n",
    "USE_GPU = True\n",
    "dtype = torch.float32 \n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "    \n",
    "   \n",
    "#!pip install GPy\n",
    "#!pip install GPyOpt\n",
    "#import GPy\n",
    "#import GPyOpt\n",
    "\n",
    "#from GPyOpt.methods import BayesianOptimization\n",
    "\n",
    "\n",
    "#def cv_score(parameters):\n",
    "#  parameters=parameters[0]\n",
    "#  lr=parameters[0]\n",
    "#  model = ResNet18()\n",
    "#  optimizer = optim.Adam(model.parameters(),lr=lr)\n",
    "#  train_part(model, optimizer, epochs = 5)\n",
    "#  acc=check_accuracy(loader_test, model)\n",
    "#  score=np.array(acc)\n",
    "#  return score\n",
    "\n",
    "#bds = [{'name': 'learning_rate', 'type': 'continuous', 'domain': (0.0001, 0.01)}]\n",
    "#optimizer = BayesianOptimization(f=cv_score, \n",
    "#                                 domain=bds,\n",
    "#                                 model_type='GP',\n",
    "#                                 acquisition_type ='EI',\n",
    "#                                 acquisition_jitter = 0.05,\n",
    "#                                 exact_feval=True, \n",
    "#                                 maximize=True)\n",
    "#optimizer.run_optimization(max_iter=10)\n",
    "#optimizer.plot_acquisition()\n",
    "#opt = optimizer.x_opt\n",
    "\n",
    "\n",
    "# define and train the network\n",
    "model = ResNet18()\n",
    "optimizer = optim.Adam(model.parameters(), lr= opt[0]) #for bayesian optimization, please uncomment the code above\n",
    "\n",
    "\n",
    "train_part(model, optimizer, epochs = 5)\n",
    "\n",
    "\n",
    "# report test set accuracy\n",
    "\n",
    "check_accuracy(loader_test, model)\n",
    "\n",
    "\n",
    "# save the model\n",
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "460cw2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
